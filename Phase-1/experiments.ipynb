{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2954d23",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.11.12)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b90fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"data/generated_data.csv\"\n",
    "\n",
    "df = pd.read_csv(FILE_PATH, header=None)\n",
    "data = df.values\n",
    "\n",
    "x = data[:, :3]\n",
    "y = np.expand_dims(a=data[:, 3], axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=27,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "x_scaler = StandardScaler().fit(x_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "# Convert to tensors and normalize to standard normal distribution\n",
    "x_train = torch.tensor(x_scaler.transform(x_train), dtype=torch.float32).to(device)\n",
    "x_test  = torch.tensor(x_scaler.transform(x_test), dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_scaler.transform(y_train), dtype=torch.float32).to(device)\n",
    "y_test  = torch.tensor(y_scaler.transform(y_test), dtype=torch.float32).to(device)\n",
    "\n",
    "# Send data to target device\n",
    "x_train, x_test = x_train.to(device), x_test.to(device)\n",
    "y_train, y_test = y_train.to(device), y_test.to(device)\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "test_ds = TensorDataset(x_test, y_test)\n",
    "\n",
    "# Batchify\n",
    "train_dataloader = DataLoader(train_ds,\n",
    "                              batch_size=32,\n",
    "                              shuffle=True)\n",
    "test_dataloader = DataLoader(test_ds,\n",
    "                             batch_size=32,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8850986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phase1Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape: int, \n",
    "                 hidden_units: int, \n",
    "                 output_shape: int):\n",
    "        super().__init__()\n",
    "        self.regression_block = nn.Sequential(\n",
    "            nn.Linear(in_features=input_shape, \n",
    "                      out_features=hidden_units),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_features=hidden_units, \n",
    "                      out_features=hidden_units),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_features=hidden_units, \n",
    "                      out_features=hidden_units),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_features=hidden_units, \n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return(self.regression_block(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f4eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Phase1Model(3, 1024, 1).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.00001)\n",
    "loss_fn = nn.MSELoss()\n",
    "epochs = 2501\n",
    "results = {\"train_loss\" : [],\n",
    "           \"test_loss\" : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f99e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    # ========== TRAINING ==========\n",
    "\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch, (x, y) in enumerate(train_dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # 1. Forward pass\n",
    "        y_preds = model(x)\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_preds, y)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # 3. Optimizer zero grad (zero the gradients)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step (gradient descent)\n",
    "        optimizer.step()\n",
    "    \n",
    "    total_train_loss = total_train_loss/len(train_dataloader)\n",
    "\n",
    "    # ========== TESTING/EVAL ==========\n",
    "    \n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (x, y) in enumerate(test_dataloader):\n",
    "                # 1. Forward pass\n",
    "                y_test_preds = model(x)\n",
    "\n",
    "                # 2. Calculate loss\n",
    "                test_loss = loss_fn(y_test_preds, y)\n",
    "                total_test_loss += test_loss.item()\n",
    "\n",
    "    total_test_loss = total_test_loss/len(test_dataloader)\n",
    "    \n",
    "    # Append to results\n",
    "    results[\"train_loss\"].append(total_train_loss)\n",
    "    results[\"test_loss\"].append(total_test_loss)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch} | Train Loss: {loss:.7f} | Test Loss: {test_loss:.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results: dict = results):\n",
    "    \"\"\"Plot the loss curves of a model\"\"\"\n",
    "    epochs = list(range(len(results[\"train_loss\"])))\n",
    "    \n",
    "    plt.plot(epochs, results[\"train_loss\"], label=\"train\")\n",
    "    plt.plot(epochs, results[\"test_loss\"], label=\"test\")\n",
    "    plt.title(\"Loss Curves\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de7159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some test points\n",
    "\n",
    "test_points = [\n",
    "    (200, 150, 25),    # Center (should be near 0)\n",
    "    (0, 0, 0),         # Far corner\n",
    "    (400, 300, 50),    # Opposite corner\n",
    "    (150, 78, 100)  # Random point\n",
    "]\n",
    "\n",
    "print(f\"{'x':>6} {'y':>6} {'z':>6} | {'Pred(scaled)':>14} {'Actual(scaled)':>16} | {'Pred(real)':>14} {'Actual(real)':>14}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for (x, y, z) in test_points:\n",
    "    # Scale input\n",
    "    inp = x_scaler.transform([[x, y, z]])\n",
    "    inp_tensor = torch.tensor(inp, dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        pred_scaled = model(inp_tensor).cpu().numpy()  # Model output (scaled)\n",
    "        pred_real = y_scaler.inverse_transform(pred_scaled)  # Real units\n",
    "\n",
    "    # Compute true values (both scaled + real)\n",
    "    actual_real = -(((x-200)**2 + (y-150)**2 + (z-25)**2)) + 20 + random.randint(-10, 10)*0.01\n",
    "    actual_scaled = y_scaler.transform([[actual_real]])[0, 0]\n",
    "\n",
    "    print(f\"{x:6d} {y:6d} {z:6d} | {pred_scaled[0,0]:14.5f} {actual_scaled:16.5f} | \"\n",
    "          f\"{pred_real[0,0]:14.5f} {actual_real:14.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding optimal parameters\n",
    "\n",
    "# Starting prediction (random values)\n",
    "x = np.array([[-1000.0, 5100.0, 3450.0]])\n",
    "\n",
    "# Scale units\n",
    "x_scaled = x_scaler.transform(x)\n",
    "\n",
    "# Convert to tensor\n",
    "x_tensor = torch.tensor(x_scaled, dtype=torch.float32, requires_grad=True, device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam([x_tensor], lr=0.1)\n",
    "epochs = 201\n",
    "\n",
    "for i in range(epochs):\n",
    "    # 1. Forward pass\n",
    "    pred_scaled = model(x_tensor)\n",
    "    \n",
    "    # 2. Calculate loss\n",
    "    loss = -pred_scaled\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 4. Loss backward (backpropagation)\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step (gradient descent)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Keep scaled inputs within reasonable bounds\n",
    "    with torch.no_grad():\n",
    "        x_tensor.clamp_(-4, 4)\n",
    "    \n",
    "    pred_real = y_scaler.inverse_transform(pred_scaled.detach().cpu().numpy())\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        print(f\"Iter {i:3d} | Pred(real): {pred_real[0,0]:.3f}\")\n",
    "\n",
    "# Convert final scaled x back to REAL domain\n",
    "x_best_scaled = x_tensor.detach().cpu().numpy()\n",
    "x_best_real = x_scaler.inverse_transform(x_best_scaled)\n",
    "\n",
    "y_best_scaled = model(x_tensor).detach().cpu().numpy()\n",
    "y_best_real = y_scaler.inverse_transform(y_best_scaled)\n",
    "\n",
    "print(\"\\n===== OPTIMAL INPUTS (REAL UNITS) =====\")\n",
    "print(\"x:\", x_best_real[0,0])\n",
    "print(\"y:\", x_best_real[0,1])\n",
    "print(\"z:\", x_best_real[0,2])\n",
    "print(\"Predicted w (speed):\", y_best_real[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98698783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waveform example for paper\n",
    "n = np.arange(-100, 2600)\n",
    "u = lambda n: np.where(n >= 0, 1, 0)\n",
    "x1 = u(n) - 2*u(n - 500) + 2*u(n - 1000) - 2*u(n - 1500) + 2*u(n - 2000)\n",
    "x2 = u(n-200) - 2*u(n - 400) + 2*u(n - 600) - 2*u(n - 800) + 2*u(n - 1000) - 2*u(n - 1200) + 2*u(n - 1400) - 2*u(n - 1600) + 2*u(n - 1800) - 2*u(n - 2000) + 2*u(n - 2200) - 2*u(n - 2400)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(n, x1, label=\"Leg 1 Pulse Waveform\", lw=5, ls=\"-\")\n",
    "plt.plot(n, x2, label=\"Leg 2 Pulse Waveform\", lw=5, ls=\"-.\")\n",
    "plt.title(\"Leg Pulse Waveforms Example\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Leg Pulse State\")\n",
    "plt.xlim(-100, 2600)\n",
    "plt.ylim(-2, 2)\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
